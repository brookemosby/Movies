{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Movie Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Cinema has become one of the highest profiting industries over the past century. The total box office revenue in North America alone amounted to $11.38 billion in 2016. With the possibility of great success, there is also a large risk of financial failure. This data exploration is motivated by answering the question what makes a movie successful. Specifically do higher budgets mean that a movie will be more profitable? Does the date of release affect the movies profit? Is the box office revenue for the opening weekend of a movie a good predictor of the profit of a movie? Answering these questions could save cinema production companies millions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraped, Downloaded & Cleaned\n",
    "To begin the data investigation, a collection of movies will be needed to gather data on. To accomplish this, movie names will be scraped from the rotten tomatoes top 100 movies for each genre. There are 17 different genres listed, although some movies are listed in multiple genres, and not every genre contains a full list of 100 movies. In total, after eliminating duplicates, there will be 937 distinct movies collected. The collection of movie names will be biased towards more successful productions, although the large selection will resolve some of the bias introduced by the selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing all libraries to be used throughout data exploration\n",
    "import re, json, requests, seaborn, warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "%matplotlib inline\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from ipyparallel import Client\n",
    "client = Client() # Only works if a cluster is running.\n",
    "dview = client[:]\n",
    "libraries = \"\"\"import re, json, requests, seaborn, warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "%matplotlib inline\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\"\"\"\n",
    "dview.execute(libraries)\n",
    "dview.block=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This code creates a list of urls containing the top 100 movies for each genre\n",
    "base_url = \"https://www.rottentomatoes.com\"\n",
    "# Start with the action and adventure genre url\n",
    "a_a = \"https://www.rottentomatoes.com/top/bestofrt/top_100_action__adventure_movies/\"\n",
    "# The url compiler below finds urls that contain lists of top 100 movies\n",
    "url_finder = re.compile( r\"/top/bestofrt/top_100_.*$\" )\n",
    "# Below we get the html text for the action and adventure genre page\n",
    "# This page also contains links to all the other top 100 pages\n",
    "# The pages that match the url compiler are collected with the find_all\n",
    "page_source = requests.get( a_a ).text\n",
    "soup = BeautifulSoup( page_source, \"html.parser\" )\n",
    "urls = soup.find_all( \"a\", href = url_finder )\n",
    "top = []\n",
    "#each url for the top 100 movie list is appended to a list to later \n",
    "#gather the movie name\n",
    "for url in urls:\n",
    "    top.append( base_url + url[ \"href\" ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Movie Data\n",
    "While the movie names are being collected from rotten tomatoes, it is convienent to collect the motion picture content rating and the rotten tomatoes score that was given for the movie and add this to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dview' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-e504abed9490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"top\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m gather_movie_names=\"\"\"\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Initialize a set of all movies so that duplicates are not added\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Initialize a list for data to be used to create DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dview' is not defined"
     ]
    }
   ],
   "source": [
    "dview.scatter(\"top\",top)\n",
    "gather_movie_names=\"\"\"\n",
    "# Initialize a set of all movies so that duplicates are not added\n",
    "all_movies = []\n",
    "# Initialize a list for data to be used to create DataFrame\n",
    "data = []\n",
    "# For each top 100 movies page \n",
    "for url in top:\n",
    "    # requesting html\n",
    "    page_source = requests.get( url ).text\n",
    "    soup = BeautifulSoup( page_source, \"html.parser\" )\n",
    "    # top 100 movies are contained in json, load this in as a dict\n",
    "    top_100 = soup.find( 'script', type = 'application/ld+json' )\n",
    "    movie_data = json.loads( top_100.text )\n",
    "    # finding the list of movies in the json dictionary\n",
    "    list_dict = movie_data[ \"itemListElement\" ]\n",
    "    # For each movie listed in top 100\n",
    "    for top_movies in list_dict:\n",
    "        # Get the rotten tomatoes page for the movie url listed\n",
    "        page_source = requests.get( top_movies[ \"url\" ] ).text\n",
    "        soup = BeautifulSoup( page_source, \"html.parser\" )\n",
    "        # Load the movie data into a dictionary\n",
    "        movie_data = json.loads( soup.find( 'script', \n",
    "                                type = 'application/ld+json' ).text )\n",
    "        # Grab the name of the movie\n",
    "        name = movie_data[ \"name\" ]\n",
    "        # This one movie causes an error if left as is, so we change the name\n",
    "        oops =\"The Good, the Bad, the Weird (Joheun-nom, Nabbeun-nom, Isanghan-nom)\"\n",
    "        if name == oops :\n",
    "            name = \"The Good, the Bad, the Weird\"\n",
    "        # Only do the following if movie data wasn't already collected\n",
    "        if name not in all_movies:\n",
    "            try:    ratings = movie_data[ 'contentRating' ]\n",
    "            except: ratings = \"\"\n",
    "            try:    scorert = movie_data[ 'aggregateRating' ][ 'ratingValue' ]\n",
    "            except: scorert = np.nan\n",
    "            # Add name, motion picture content rating, and rotten tomatoes score to data list\n",
    "            data.append( [ name, ratings, scorert ] )\n",
    "        # Add movie name to the list of movie names so it is accounted for\n",
    "        all_movies.append( name )\n",
    "        \"\"\"\n",
    "dview.execute(gather_movie_names)\n",
    "data_scattered = dview.pull(\"data\")\n",
    "data = []\n",
    "for data_piece in data_scattered:\n",
    "    for item in data_piece:\n",
    "        data.append(item)\n",
    "all_movies_scattered = dview.pull(\"all_movies\")\n",
    "all_movies = []\n",
    "for data_piece in all_movies_scattered:\n",
    "    for item in data_piece:\n",
    "        all_movies.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-45291799cf68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0msearch_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmovie\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# Press Enter.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0msearch_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mbrowser1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'poster'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0msoup1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mbrowser1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    350\u001b[0m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[0;32m    351\u001b[0m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[1;32m--> 352\u001b[1;33m                        'value': keys_to_typing(value)})\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;31m# RenderedWebElement Items\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTemplate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubstitute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparsed_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m                 \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brooke\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#now we are looking at IMDB top 10,000 movies to find more data\n",
    "all_movies = []\n",
    "data = []\n",
    "url  = \"http://www.imdb.com/list/ls063676189/\"\n",
    "url1 = \"https://www.rottentomatoes.com/\"\n",
    "browser  = webdriver.Chrome()\n",
    "browser1 = webdriver.Chrome()\n",
    "browser.get( url )\n",
    "browser1.get( url1 )\n",
    "for _ in range(99):\n",
    "    soup = BeautifulSoup( browser.page_source, \"html.parser\" )\n",
    "    names = soup.find_all( \"h3\",{\"class\":\"lister-item-header\"} )\n",
    "    for name in names:\n",
    "        movie = name.text.split(\"\\n\")[2]\n",
    "        if movie not in all_movies:\n",
    "            # Get the search bar, type in movie name, and press Enter.\n",
    "            search_bar = browser1.find_element_by_name( \"search\" )\n",
    "            # Clear any pre-set text.\n",
    "            search_bar.clear() \n",
    "            # Searching for the name of the movie\n",
    "            search_bar.send_keys( movie ) \n",
    "            # Press Enter.\n",
    "            search_bar.send_keys( Keys.RETURN ) \n",
    "            browser1.find_element_by_class_name('poster').click()\n",
    "            soup1 = BeautifulSoup( browser1.page_source, \"html.parser\" )\n",
    "            # Load the movie data into a dictionary\n",
    "            movie_data = json.loads( soup1.find( 'script', \n",
    "                                    type = 'application/ld+json' ).text )\n",
    "            try:    ratings = movie_data[ 'contentRating' ]\n",
    "            except: ratings = \"\"\n",
    "            try:    scorert = movie_data[ 'aggregateRating' ][ 'ratingValue' ]\n",
    "            except: scorert = np.nan\n",
    "            # Add name, motion picture content rating, and rotten tomatoes score to data list\n",
    "            data.append( [ movie, ratings, scorert ] )\n",
    "            # Add movie name to the list of movie names so it is accounted for\n",
    "            all_movies.append( movie )\n",
    "    browser.find_element_by_class_name('next-page').click()\n",
    "    \n",
    "#after all this click on the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The Shawshank Redemption', 'R', 91]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Monetary Information on Each Movie\n",
    "After accumulating movie names, motion picture content rating, and the rotten tomatoes score, the dataset is still missing information on the movie budget, opening weekend revenue, and gross income, which will provide the numerical data points necessary to understand the factors that make a movie successful. The data points will be collected from IMDB, which is a reputable source for information, according to their website, \n",
    "\n",
    ">\"we [IMDB] actively gather information from and verify items with studios and \n",
    "filmmakers\".\n",
    "\n",
    "While collecting the data points, it will be convient and valuable to find the release date of the movie and add to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(data)\n",
    "dview.scatter(\"data\",data)\n",
    "movie_command = \"\"\"\n",
    "# url to get to imdb\n",
    "base_url = \"http://www.imdb.com/\"\n",
    "browser = webdriver.Chrome()\n",
    "browser.get( base_url )\n",
    "# For each movie thats already been collected\n",
    "for i in range( len( data ) ):\n",
    "    # Get the search bar, type in movie name, and press Enter.\n",
    "    search_bar = browser.find_element_by_id( \"navbar-query\" )\n",
    "    # Clear any pre-set text.\n",
    "    search_bar.clear() \n",
    "    # Searching for the name of the movie\n",
    "    search_bar.send_keys( data[ i ][ 0 ] ) \n",
    "    # Press Enter.\n",
    "    search_bar.send_keys( Keys.RETURN ) \n",
    "    soup = BeautifulSoup( browser.page_source, \"html.parser\" )\n",
    "    # Look at the search table results and choose the first result\n",
    "    table = soup.find( name = \"table\" )\n",
    "    link = table.find_all( name = \"td\" )[ 1 ]\n",
    "    url = base_url + link.find( name = \"a\" )[ \"href\" ]\n",
    "    # Get page for first movie result\n",
    "    browser.get( url ) \n",
    "    soup = BeautifulSoup( browser.page_source, \"html.parser\" )\n",
    "    # All information needed is contained in h4 tabs\n",
    "    tab = soup.find_all( name = \"h4\" )\n",
    "    B, O, G, R = False, False, False, False\n",
    "    for j in tab:\n",
    "        if j.text == \"Release Date:\" :\n",
    "            data[ i ].append( ( \" \" ).join( j.next_sibling.split() ) )\n",
    "            R = True\n",
    "        if j.text == \"Budget:\":\n",
    "            data[ i ].append( ( \" \" ).join( j.next_sibling.split() ) )\n",
    "            B = True\n",
    "        if j.text == \"Opening Weekend:\":\n",
    "            data[ i ].append( ( \" \" ).join( j.next_sibling.split( ) ) )\n",
    "            O = True\n",
    "        if j.text == \"Gross:\":\n",
    "            data[ i ].append( ( \" \" ).join( j.next_sibling.split( ) ) )\n",
    "            G = True\n",
    "    # Inserting NaNs for missing values\n",
    "    if not R: data[ i ].insert( 3, np.nan )\n",
    "    if not B: data[ i ].insert( 4, np.nan )\n",
    "    if not O: data[ i ].insert( 5, np.nan )\n",
    "    if not G: data[ i ].insert( 6, np.nan )  \n",
    "browser.close()\n",
    "\"\"\"\n",
    "dview.execute(movie_command)\n",
    "data_scattered = dview.pull(\"data\")\n",
    "data = []\n",
    "for data_piece in data_scattered:\n",
    "    for item in data_piece:\n",
    "        data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attempting to find information on dvd sales for movie, along with more financial info\n",
    "#maybe look to gather some categorical data\n",
    "#variables to gather runing time, ranking in box office, worldwide, adjusted, video sales if available, Production countries\n",
    "#any empty variables can be filled from this source\n",
    "#look to add more movies... maybe try to find netflix data\n",
    "#if we have more movies then dropping movies with incomplete data hopefully wont have as much of an impact\n",
    "#we want to look at more predictor variables\n",
    "# url to get to imdb\n",
    "\n",
    "base_url = \"https://www.the-numbers.com/weekly-dvd-sales-chart\"\n",
    "browser = webdriver.Chrome()\n",
    "browser.get( base_url )\n",
    "# For each movie thats already been collected\n",
    "for i in range( len( data ) ):\n",
    "    # Get the search bar, type in movie name, and press Enter.\n",
    "    search_bar = browser.find_element_by_name( \"searchterm\" )\n",
    "    # Clear any pre-set text.\n",
    "    search_bar.clear() \n",
    "    # Searching for the name of the movie\n",
    "    search_bar.send_keys( data[ i ][ 0 ] ) \n",
    "    # Press Enter.\n",
    "    search_bar.send_keys( Keys.RETURN ) \n",
    "    movie_link = browser.find_element_by_name( \"searchterm\" )\n",
    "    soup = BeautifulSoup( browser.page_source, \"html.parser\" )\n",
    "    break\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len( data )\n",
    "columns = [ \"Name\", \"Rating\", \"Score\", \"Release\", \"Budget\", \"Open\", \"Gross\" ]\n",
    "df = pd.DataFrame( data, index = np.arange( n ), columns = columns )\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "After gathering each data point, the data set is complete, although the information is not clean or uniform. The first step to clean up the names and release dates, will be to remove any phrases in parenthesis across the rows of the DataFrame. Following the removal of parenthesis, will be the removal of all commas across each column in the DataFrame. Removing commas will make it easier to convert monetary amounts to ints. Next each date in the Release column will be changed to a pandas date object, which will simplify any calculations that rely on the release date of the movie. Finally each monetary amount will be converted into an int, while creating place holder columns for the currency type of the budget and opening weekend revenue. The gross income column of the movie DataFrame is listed in USD solely, so this value will not need a place holder column for it. The dataset is now cleaned, although the information is not given in uniform units, which will need to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df\n",
    "def remove_parenthesis( row ):\n",
    "    \"\"\"\n",
    "    Function accepts a pd.Series describing a row of a DataFrame. For each \n",
    "    value in the row the string before the first opening parenthesis becomes \n",
    "    the new value. The new pd.Series of the row is returned, without any \n",
    "    phrases in parenthesis.\n",
    "    \"\"\"\n",
    "    row = [ str( value ).split( \"(\" )[ 0 ] for value in row ]\n",
    "    return pd.Series( row )\n",
    "def remove_comma( row ):\n",
    "    \"\"\"\n",
    "    Function accepts a pd.Series describing a row of a DataFrame. For each \n",
    "    value in the row the string is split by commas, then joined without \n",
    "    them. The new pd.Series of the row is returned, without commas.\n",
    "    \"\"\"\n",
    "    row = [ ( \"\" ).join( str( value ).split( \",\" ) ) for value in row ]\n",
    "    return pd.Series( row )\n",
    "def _type( currency ):\n",
    "    \"\"\"\n",
    "    Function accepts a value representing a monetary amount. If the value \n",
    "    is a string \"nan\", then np.nan is returned. If the monetary amount split\n",
    "    by spaces has length greater than one, then this implies that there is a \n",
    "    string, such as AUD, before the monetary amount, this currency indicator \n",
    "    will be returned. If the monetary amount split by spaces only consist of \n",
    "    one item, that implies a symbol, such as $ is before the monetary amount. \n",
    "    This currency indicator will be returned.\n",
    "    \"\"\"\n",
    "    if currency == \"nan\":\n",
    "        return np.nan\n",
    "    currency_indicator = currency.split()\n",
    "    if len( currency_indicator ) > 1:\n",
    "        return currency_indicator[ 0 ]\n",
    "    else:\n",
    "        return currency[ 0 ]\n",
    "def _int( currency ):\n",
    "    \"\"\"\n",
    "    Function accepts a value representing a monetary amount. If the value is \n",
    "    a string \"nan\", then np.nan is returned. If the monetary amount split by\n",
    "    spaces has length greater than one, then this implies that there is a \n",
    "    string, such as AUD, before the monetary amount, the monetary amount \n",
    "    after the currency indicator will be returned as an int. If the monetary \n",
    "    amount split by spaces only consist of one item, that implies a symbol,\n",
    "    such as $ is before the monetary amount. The monetary amount after the \n",
    "    currency indicator will be returned as an int.\n",
    "    \"\"\"\n",
    "    if currency == \"nan\":\n",
    "        return np.nan\n",
    "    currency_amount = currency.split()\n",
    "    if len( currency_amount ) > 1:\n",
    "        return int( currency_amount[ 1 ] )\n",
    "    else:\n",
    "        return int( currency[ 1: ] )\n",
    "    \n",
    "df1      = df1.apply( remove_parenthesis, axis = 1 )\n",
    "df1      = df1.apply( remove_comma,       axis = 1 )\n",
    "df1[ 3 ] = df1[ 3 ].apply( lambda x: pd.to_datetime( str( x ) ) )\n",
    "df1[ 7 ] = df1[ 4 ].apply( _type )\n",
    "df1[ 8 ] = df1[ 5 ].apply( _type )\n",
    "df1[ 2 ] = df1[ 2 ].apply( lambda x: float( x )  )\n",
    "df1[ 4 ] = df1[ 4 ].apply( _int  ) #column 4 units described by column 7\n",
    "df1[ 5 ] = df1[ 5 ].apply( _int  ) #column 5 units described by column 8\n",
    "df1[ 6 ] = df1[ 6 ].apply( _int  ) #column 6 is all in USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Currency to USD\n",
    "The next step in unifying the currency units is to convert all monetary amounts into USD. Converting each column to USD will make comparisons valid, and is accomplished by using a dataset which contains the exchange rates for 26 different currencies to USD, for dates throughout the past century. For currencies not listed in USD, the release date of the movie will be used to find the accurate exchange rate to USD, after which the currency will be converted to USD. Once the conversations are calculated, the place holder columns describing the original currency are dropped, resulting in a clean and uniform dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e_r_columns = [ \"Dates\",   \"€\",   \"£\",  \"BRL\", \"CNY\", \"DKK\", \"INR\", \"JPY\", \n",
    "                  \"KRW\", \"MYR\", \"MXN\",  \"NOK\", \"SEK\", \"ZAR\", \"SGD\", \"CHF\", \n",
    "                  \"TWD\", \"THB\", \"VEB\", \"NBDI\", \"NMC\", \"NOI\", \"AUD\", \"NZD\", \n",
    "                  \"CAD\", \"HKD\", \"LKR\" ]\n",
    "exchange_rates = pd.read_csv( \"exchange_rates.csv\", \n",
    "                             skiprows = [ 0, 1, 2, 4, 5, 6 ] )\n",
    "exchange_rates.columns = e_r_columns\n",
    "exchange_rates[ \"Dates\" ] = exchange_rates[ \"Dates\" ].apply( \n",
    "    lambda x: pd.to_datetime( str( x ) ) )\n",
    "\n",
    "def change_to_USD(row):\n",
    "    \"\"\"\n",
    "    Function accepts a pd.Series representing a pd.DataFrame row, then \n",
    "    changes the budget and opening weekend monetary amount to USD, and\n",
    "    returns the new updated pd.Series with the correct amounts.\n",
    "    \"\"\"\n",
    "    date = row[ 3 ]\n",
    "    foreign_budget = row[ 4 ]\n",
    "    foreign_open   = row[ 5 ]\n",
    "    indicator_budget = row[ 7 ]\n",
    "    indicator_open   = row[ 8 ]\n",
    "    \n",
    "    if indicator_budget != \"$\" and indicator_budget != \"nan\":\n",
    "        try:\n",
    "            cur_rate = exchange_rates[ indicator_budget ][ \n",
    "                exchange_rates[ \"Dates\" ] == date ].values[ 0 ]\n",
    "            row[ 4 ] = int( foreign_budget ) / float( cur_rate )\n",
    "        except:\n",
    "            row[ 4 ] = np.nan\n",
    "    if indicator_open   != \"$\" and indicator_open   != \"nan\":\n",
    "        try:\n",
    "            cur_rate = exchange_rates[ indicator_open   ][ \n",
    "                exchange_rates[ \"Dates\" ] == date ].values[ 0 ]\n",
    "            row[ 5 ] = int( foreign_open )  / float( cur_rate )\n",
    "        except:\n",
    "            row[ 5 ] = np.nan\n",
    "    return row\n",
    "\n",
    "df1 = df1.apply( change_to_USD, axis = 1 )\n",
    "\n",
    "# Delete currency indicator columns\n",
    "del df1[ 7 ], df1[ 8 ]\n",
    "df = df1\n",
    "df.columns = columns\n",
    "df.sample( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv( \"Cleaned_Data.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Some adjustments to the dataset will be needed in order to better understand the data. First it will be beneficial to create a column corresponding to the decades of the movies' release date. A column that identifies the profit of the movie will be crucial in determining the financial success of the movie. To create a Profit column, the budget of the movie will be subtracted from the gross income. Finally, there is one remaining issue to be addressed. Because the movies in the dataset span the past century the monetary amounts are not adjusted for inflation, making them difficult to compare directly. To resolve the disagreement between the monetary amounts, a dataset containing the CPI for each year from 1914 will used to adjust for inflation. The CPI, Consumer Price Index, describes the amount of purchasing power the average consumer has. To account for inflation, the current CPI is divided by the CPI of the year when the movie was released to obtain a ratio of purchasing power. The monetary amounts are multiplied by this ratio, resulting in a new monetary amount corresponding to the approximate amount with today's purchasing power. The budget, opening weekend revenue, gross income, and profit of each movie will be adjusted for inflation, and placed into new columns. With the adjusted inflation columns, relationships between variables may become more apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with missing data\n",
    "df = df.dropna()\n",
    "# Calculating the decade for the release date\n",
    "df[ \"Decade\" ] = df[ \"Release\" ].apply( lambda x: ( ( x.year % 1900 ) // 10 ) * 10 + 1900  ) \n",
    "df[ \"Profit\" ] = df[ \"Gross\" ] - df[ \"Budget\" ]\n",
    "\n",
    "# Adjusting for inflation\n",
    "inflation_rates = pd.read_csv( \"inflation_rates.csv\", index_col = \"Year\")\n",
    "current_CPI = float( inflation_rates[ \"November\" ].iloc[-1] )\n",
    "def change_to_current(row):\n",
    "    \"\"\"\n",
    "    Function accepts pd.Series describing a row in pd.DataFrame\n",
    "    Then creates new columns adjusting for inflation by multiplying by CPI ratio\n",
    "    Function returns new pd.Series describing row in pd.DataFrame\n",
    "    \"\"\"\n",
    "    year_release  = row[ \"Release\" ].year\n",
    "    month_release = row[ \"Release\" ].month - 1\n",
    "    value_CPI = float( inflation_rates.loc[ year_release ][ 12 ] )\n",
    "    if value_CPI == 0 :\n",
    "        row[ \"Budget_Adjusted\" ], row[ \"Gross_Adjusted\"  ] = np.nan, np.nan\n",
    "        row[ \"Open_Adjusted\"   ], row[ \"Profit_Adjusted\" ] = np.nan, np.nan\n",
    "    else:\n",
    "        row[ \"Budget_Adjusted\" ] = row[ \"Budget\" ] * current_CPI / value_CPI\n",
    "        row[ \"Gross_Adjusted\"  ] = row[ \"Gross\"  ] * current_CPI / value_CPI\n",
    "        row[ \"Open_Adjusted\"   ] = row[ \"Open\"   ] * current_CPI / value_CPI\n",
    "        row[ \"Profit_Adjusted\" ] = row[ \"Profit\" ] * current_CPI / value_CPI\n",
    "    return row\n",
    "df = df.apply( change_to_current, axis = 1 )\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv( \"Engineered_Data.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data\n",
    "The next step to understanding relationships between different variables is visualizing the data. The first step is to investigate how the data has changed over the past century, and compare the change between variables, which may give some insight into relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 17, 8 ) )\n",
    "ax4      = plt.subplot( 414 )\n",
    "ax1, ax2 = plt.subplot( 411, sharex = ax4 ), plt.subplot( 412, sharex = ax4 )\n",
    "ax3      = plt.subplot( 413, sharex = ax4 )\n",
    "df.plot( y = \"Gross\",  x = \"Release\", ax = ax1, title = \"Gross by Release Date\" )\n",
    "df.plot( y = \"Budget\", x = \"Release\", ax = ax2, title = \"Budget by Release Date\" )\n",
    "df.plot( y = \"Open\",   x = \"Release\", ax = ax3, title = \"Opening Weekend by Release Date\" )\n",
    "df.plot( y = \"Profit\", x = \"Release\", ax = ax4, title = \"Profit by Release Date\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing the graph above, it is apparrent there has been an exponential increase in movie budgets, opening weekend revenues, gross income and profit. It is still unclear how much of this increase is due to inflation over time. Investigating how inflation has changed these four variables is the next rational step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 17, 8 ) )\n",
    "ax4      = plt.subplot( 414 )\n",
    "ax1, ax2 = plt.subplot( 411, sharex = ax4 ), plt.subplot( 412, sharex = ax4 )\n",
    "ax3      = plt.subplot( 413, sharex = ax4 )\n",
    "df.plot( y = \"Gross_Adjusted\",  x = \"Release\", ax = ax1, \n",
    "        title = \"Inflation Adjusted Gross by Release Date\" )\n",
    "df.plot( y = \"Budget_Adjusted\", x = \"Release\", ax = ax2, \n",
    "        title = \"Inflation Adjusted Budget by Release Date\" )\n",
    "df.plot( y = \"Open_Adjusted\",   x = \"Release\", ax = ax3, \n",
    "        title = \"Inflation Adjusted Opening Weekend by Release Date\" )\n",
    "df.plot( y = \"Profit_Adjusted\", x = \"Release\", ax = ax4, \n",
    "        title = \"Inflation Adjusted Profit by Release Date\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the variables in the graphs above, it looks as though the the gross income and profit have decreased over time, while the opening weekend revenue and budget have increased over time. It is important to note that there are significantly more movies released in later decades, as demonstrated in the histogram below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"Decade\"].hist( figsize = ( 17, 2 ) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that the movie with the highest adjusted budget was Titanic, the movie with the highest opening weekend revenue was Harry Potter and the Deathly Hallows - Part 2 and the movie with both the highest gross income and profit was Gone with the Wind. After looking at how the monetary variables are distributed over the past century, it seems reasonable to investigate how the variables are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 17,3 ) )\n",
    "seaborn.heatmap( df[[\"Decade\", \"Budget_Adjusted\", \"Gross_Adjusted\", \"Open_Adjusted\", \n",
    "                     \"Profit_Adjusted\"]].corr(), annot = True, fmt = \".001f\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap above gives the strengths of the correlations coefficients, on a scale of -1.0 to 1.0. 1.0 is perfectly positively correlated, and -1.0 is perfectly negatively correlated, meaning each variable will positively correlate to itself perfectly. The heatmap gives some interesting relationships between variables. There were no strong correlations between the unadjusted variables, and thus were excluded from the heatmap above. The first relationship worth notice, is that the later in the century a movie was produced, the worse the adjusted profit and adjusted gross income of the movie would be. A second relationship that needs investigation is the perfect positive correlation between the adjusted gross and the adjusted profit. Since the adjusted profit is calculated from the adjusted gross income, it is reasonable that they would be strongly positively correlated, although extremely unlikely that this would be a perfect relationship. The correlation coefficient for the relationship between the adjusted gross income and the adjusted profit is 0.978601533586, which is strongly positive, although not perfect, as the rounded number in the heatmap would suggest. It is interesting to note that from this heatmap, it seems as though the adjusted budget has little correlation to the adjusted profit. The relationships between the adjusted profit for a movie, and the adjusted budget, adjusted gross income, and adjusted opening weekend revenue still need to be investigated. There may be some intuition to gain from looking at the linear regression for each relationship, which would be the next step in the data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 17,3 ) )\n",
    "ax1 = plt.subplot( 131 )\n",
    "ax2, ax3 = plt.subplot( 132, sharey = ax1 ), plt.subplot( 133, sharey = ax1 )\n",
    "seaborn.regplot( x = \"Budget_Adjusted\", y =\"Profit_Adjusted\", ax = ax1, data = df ) \n",
    "seaborn.regplot( x = \"Open_Adjusted\",   y =\"Profit_Adjusted\", ax = ax2, data = df ) \n",
    "seaborn.regplot( x = \"Gross_Adjusted\",  y =\"Profit_Adjusted\", ax = ax3, data = df ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs above, it is clear that the gross income is the best estimator for the profit, mainly because profit is calculated from the gross income. However the gross income is only useful to estimate the profit, if the variable for the budget is not available. The second best variable for predicting the profit is the opening weekend revenue. The opening weekend revenue may be a more useful predictor for profit than the gross income, because it can give insight into what the profit of a movie may be before it leaves theaters. It is interesting that there is almost no correlation between the budget of a movie, and the profit the movie makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[[\"Budget_Adjusted\",\"Open_Adjusted\",\"Gross_Adjusted\",\"Profit_Adjusted\"]].plot( \n",
    "    kind = \"kde\", colormap='Set1', figsize = (17,5) )\n",
    "plt.xlim(-.5e8,1e8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distributions above we can see that there is a large variance between the adjusted gross income and the adjusted profit, with almost not peak. Whereas, the adjusted budget and the adjusted open weekend revenue are less varied distributions. The adjusted budget has little or no correlation to the adjusted profit, which suggests that the regardless of the budget of a movie, there is still a high risk to lose alot of money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Unfortunately there does not seem to be a large correlation between the budget of a movie, and the profit of the production. This suggests that spending large amounts of money on a movie production does not necessarily pay off.  After looking into all the dataset variables, there was little information to be gained from the motion picture content rating, the rotten tomatoes score, and the unadjusted monetary amounts. One of the most useful predictors for the profit of a movie seems to be the opening weekend revenue, which is intuitive. A larger dataset of movies could present more correlations, due to time constraints this dataset was limited to ~1000 movie titles.  More information that could be used as predictors for the profit of a movie would be money and time spent into marketing the movie, and the amount of different trailers released. These variables may play a larger role and factor into what makes a movie more profitable and successfull. Also, collecting information on DVD sales once the movie left the theater could give more insight into just how profitable, or successful the movie was."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
